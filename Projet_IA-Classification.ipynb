{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projet IA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression Logistique"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chargement des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.31108846, -0.66194603,  0.24970918, ...,  2.        ,\n",
       "         1.        ,  1.        ],\n",
       "       [ 0.71645169, -0.66194603, -1.56559001, ...,  1.        ,\n",
       "         2.        ,  2.        ],\n",
       "       [-0.1813684 ,  0.25240281, -1.56559001, ...,  2.        ,\n",
       "         0.        ,  3.        ],\n",
       "       ...,\n",
       "       [-0.01862868, -1.57629486,  0.24970918, ...,  2.        ,\n",
       "         1.        ,  5.        ],\n",
       "       [-1.26787221, -1.57629486,  0.24970918, ...,  2.        ,\n",
       "         1.        ,  3.        ],\n",
       "       [ 0.60638618,  1.16675164, -0.65794042, ...,  2.        ,\n",
       "         1.        ,  1.        ]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "DATA_MERGE_PATH = os.path.join(\"data\")\n",
    "def DataMerge(data_merge_path=DATA_MERGE_PATH):\n",
    "    csv_path = os.path.join(data_merge_path, \"DataMerge.csv\")\n",
    "    return pd.read_csv(csv_path) \n",
    "\n",
    "X = DataMerge()\n",
    "\n",
    "X_labels = X[\"Attrition\"].copy()\n",
    "X = X.drop(\"Attrition\", axis=1)\n",
    "\n",
    "#remplace gender male=1 / female=0\n",
    "X.Gender.replace(to_replace=dict(Male=1, Female=0), inplace=True)\n",
    " \n",
    "num_pipeline = Pipeline([\n",
    "        ('imputer', SimpleImputer(strategy=\"median\")),\n",
    "        ('std_scaler', StandardScaler()),\n",
    "    ])\n",
    " \n",
    "X_num = X.select_dtypes(include=[np.number])\n",
    " \n",
    "num_attribs = list(X_num)\n",
    "cat_attribs = [\"MaritalStatus\", \"JobRole\", \"BusinessTravel\", \"Department\", \"EducationField\"]\n",
    " \n",
    "full_pipeline = ColumnTransformer([\n",
    "        (\"num\", num_pipeline, num_attribs),\n",
    "        (\"cat\", OrdinalEncoder(), cat_attribs),\n",
    "    ])\n",
    " \n",
    "X_prepared = full_pipeline.fit_transform(X)\n",
    "\n",
    "\n",
    "#Visualisation\n",
    "pd.set_option('display.max_columns', None)\n",
    "X_prepared\n",
    "\n",
    "X_full_set, X_test_set, Y_full_set, Y_test_set = train_test_split(X_prepared, X_labels, test_size=0.8, random_state=42) #SOLUTION\n",
    "X_test_set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Préparation de la régression logistique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "clf = LogisticRegression(random_state=0, solver='lbfgs', max_iter=100)\n",
    "clf.fit(X_test_set, Y_test_set)\n",
    "y_pred = clf.predict(X_full_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation du modèle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calcul du score de précision de notre regression logistique entre les valeurs de tests prédites et les valeurs de tests connus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "85.46511627906976"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "accuracy = accuracy_score(Y_full_set, y_pred)\n",
    "accuracy_percentage = 100 * accuracy\n",
    "accuracy_percentage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On obtient une précision de **85.46%** sur notre jeu de test."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On calcul ensuite l'erreur quadratique moyenne pour comparer avec les autres algorithmes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3812464258315117"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "lr_mse = mean_squared_error(Y_full_set, y_pred)\n",
    "lr_rmse = np.sqrt(lr_mse)\n",
    "lr_rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On obtient une erreur de 0.38 ce qui est plutôt élevé par rapport à d'autres modèles d'entrainement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
