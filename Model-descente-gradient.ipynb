{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression lineaire"
   ]
  },
  {
   "source": [
    "### Recuperation des donnés\n",
    "\n",
    "On vient récuperer les données préparés et stockés dans DataMerge.csv.   \n",
    "Ensuite on construit nos matrices avec une pipeline qui supprime les données incohérentes, réduit les éléments numériques à la même échelle et encode les valeurs non-numériques.\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "DATA_MERGE_PATH = os.path.join(\"data\")\n",
    "def DataMerge(data_merge_path=DATA_MERGE_PATH):\n",
    "    csv_path = os.path.join(data_merge_path, \"DataMerge.csv\")\n",
    "    return pd.read_csv(csv_path) \n",
    "\n",
    "X = DataMerge()\n",
    "\n",
    "\n",
    "X_labels = X[\"Attrition\"].copy()\n",
    "X = X.drop(\"Attrition\", axis=1)\n",
    "\n",
    "#remplace gender male=1 / female=0\n",
    "X.Gender.replace(to_replace=dict(Male=1, Female=0), inplace=True)\n",
    "X_full_set, X_test_set, Y_full_set, Y_test_set = train_test_split(X, X_labels, test_size=0.8, random_state=42) #SOLUTION\n",
    "num_pipeline = Pipeline([\n",
    "        ('imputer', SimpleImputer(strategy=\"median\")),\n",
    "        ('std_scaler', StandardScaler()),\n",
    "    ])\n",
    " \n",
    "X_num = X.select_dtypes(include=[np.number])\n",
    " \n",
    "num_attribs = list(X_num)\n",
    "cat_attribs = [\"MaritalStatus\", \"JobRole\", \"BusinessTravel\", \"Department\", \"EducationField\"]\n",
    " \n",
    "full_pipeline = ColumnTransformer([\n",
    "        (\"num\", num_pipeline, num_attribs),\n",
    "        (\"cat\", OrdinalEncoder(), cat_attribs),\n",
    "    ])\n",
    " \n",
    "X_test_prepared = full_pipeline.fit_transform(X_test_set)\n",
    "X_full_prepared = full_pipeline.fit_transform(X_full_set)\n",
    "\n"
   ]
  },
  {
   "source": [
    "Utilisation du modèle de régression linéaire. Le modèle cherche à determiner une corréleation entre les données étiquetable et les données etiquettes à travers une fonction.\n",
    "Après avoir entrainer le modèle, on test les prédictions sur quelques instances aléatoires."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Predictions: [0.04357974 0.29254581 0.21823917 0.01288901 0.30235911]\nLabels: [0, 1, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "lin_reg = LinearRegression()\n",
    "lin_reg.fit(X_test_prepared, Y_test_set)\n",
    "# On applique le full_pipeline sur quelques instances :\n",
    "some_data = X.iloc[:5]\n",
    "some_labels = X_labels.iloc[:5]\n",
    "some_data_prepared = full_pipeline.transform(some_data)\n",
    "\n",
    "# Et on effectue la prédiction :\n",
    "print(\"Predictions:\", lin_reg.predict(some_data_prepared))\n",
    "print(\"Labels:\", list(some_labels)) # vraies valeurs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation du modele\n",
    "\n",
    "On vient calculer la fiabilité de la régression linéaire pour ensuite comparer les modèles entre eux."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.3437275531620965"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from math import *\n",
    "X_predictions = lin_reg.predict(X_test_prepared)\n",
    "lin_rmse = sqrt(mean_squared_error(Y_test_set, X_predictions ))\n",
    "lin_rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Arbre de décision\n",
    "\n",
    "Entrainement d'un arbre de décision."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "tree_reg = DecisionTreeRegressor(random_state=42)\n",
    "tree_reg.fit(X_test_prepared, Y_test_set)\n",
    "X_predictions = tree_reg.predict(X_test_prepared)\n",
    "tree_mse = mean_squared_error(Y_test_set, X_predictions)\n",
    "tree_rmse = np.sqrt(tree_mse)\n",
    "tree_rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ici l'évaluation du modèle returne 0 soit un apprentissage parfait. Or ceci est impossible en Machine Learning. On peut donc en déduire que le modèle à fait de l'overfitting.   \n",
    "En effet celui ci a appri toutes les combinaison possible du jeu de données qui lui a été soumis pour le fitting. "
   ]
  },
  {
   "source": [
    "# Cross Validation\n",
    "\n",
    "La cross-validation permet d'evaluer la fiabilité du model en testant des échantillons du jeu de données."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Arbre de decision"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Scores: [0.23501608 0.27492071 0.27492071 0.17882042 0.21566555 0.26413527\n 0.23501608 0.24707592 0.29034863 0.25289027]\nMean: 0.2468809638564653\nStandard deviation: 0.031119034953955408\nScores: [0.43133109 0.44460591 0.45749571 0.47003216 0.44460591 0.47003216\n 0.43133109 0.45749571 0.49415185 0.43133109]\nMean: 0.4532412696071809\nStandard deviation: 0.01965464355420423\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "scores = cross_val_score(tree_reg, X_test_prepared, Y_test_set,\n",
    "                         scoring=\"neg_mean_squared_error\", cv=10)\n",
    "tree_rmse_scores = np.sqrt(-scores)\n",
    "#Calcul du score avec le jeu de validation\n",
    "new_scores = cross_val_score(tree_reg, X_full_prepared, Y_full_set,\n",
    "                         scoring=\"neg_mean_squared_error\", cv=10)\n",
    "new_tree_rmse_scores = np.sqrt(-new_scores)\n",
    "def display_scores(scores):\n",
    "    print(\"Scores:\", scores)\n",
    "    print(\"Mean:\", scores.mean())\n",
    "    print(\"Standard deviation:\", scores.std())\n",
    "\n",
    "display_scores(tree_rmse_scores)\n",
    "display_scores(new_tree_rmse_scores)"
   ]
  },
  {
   "source": [
    "On voit ici que la fiabilité n'est plus a 0. Donc le modèle n'est pas assez performant sur un jeu de donné inconnu."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Regression Lineaire\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Scores: [0.33465968 0.33240475 0.37284842 0.32991516 0.33355488 0.32199852\n 0.36119033 0.36038367 0.3699375  0.34570255]\nMean: 0.3462595458753298\nStandard deviation: 0.017418379453167095\n"
     ]
    }
   ],
   "source": [
    "scores = cross_val_score(lin_reg, X_test_prepared, Y_test_set,\n",
    "                         scoring=\"neg_mean_squared_error\", cv=10)\n",
    "lin_rmse_scores = np.sqrt(-scores)\n",
    "display_scores(lin_rmse_scores)"
   ]
  },
  {
   "source": [
    "# Foret Aléatoire"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.0890192035723257"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "forest_reg = RandomForestRegressor(n_estimators=10, random_state=42)\n",
    "forest_reg.fit(X_test_prepared, Y_test_set)\n",
    "X_predictions = forest_reg.predict(X_test_prepared)\n",
    "forest_rmse = mean_squared_error(Y_test_set, X_predictions)\n",
    "forest_rmse = np.sqrt(forest_rmse)\n",
    "forest_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Scores: [0.20324404 0.23259157 0.22938239 0.18677184 0.19199079 0.1768589\n 0.2342107  0.23674144 0.23020466 0.1996363 ]\nMean: 0.2121632628353299\nStandard deviation: 0.02159632065555168\n"
     ]
    }
   ],
   "source": [
    "forest_scores = cross_val_score(forest_reg, X_test_prepared, Y_test_set,\n",
    "                                scoring=\"neg_mean_squared_error\", cv=10)\n",
    "forest_rmse_scores = np.sqrt(-forest_scores)\n",
    "display_scores(forest_rmse_scores)"
   ]
  },
  {
   "source": [
    "## Support Vector Regression "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.3728904196607226"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "from sklearn.svm import SVR\n",
    "svr_regr = SVR(kernel=\"linear\")\n",
    "svr_regr.fit(X_test_prepared, Y_test_set)\n",
    "X_predictions = svr_regr.predict(X_test_prepared)\n",
    "svr_mse = mean_squared_error(Y_test_set, X_predictions)\n",
    "svr_rmse = np.sqrt(svr_mse)\n",
    "svr_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Scores: [0.34871446 0.35857218 0.41001831 0.36815984 0.35532436 0.32454261\n 0.39559787 0.3955853  0.40716693 0.35531165]\nMean: 0.3718993498620441\nStandard deviation: 0.02709461442729581\n"
     ]
    }
   ],
   "source": [
    "svr_regr_scores = cross_val_score(svr_regr, X_test_prepared, Y_test_set,\n",
    "                                scoring=\"neg_mean_squared_error\", cv=10)\n",
    "svr_regr_rmse_scores = np.sqrt(-svr_regr_scores)\n",
    "display_scores(svr_regr_rmse_scores)"
   ]
  },
  {
   "source": [
    "## Grid Search\n",
    "\n",
    "Recherche des meilleurs paramètres.\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'bootstrap': False, 'max_features': 3, 'n_estimators': 10}"
      ]
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = [\n",
    "    # essaye 12 (3×4) combinaisons des hyperparametres\n",
    "    {'n_estimators': [3, 10, 30], 'max_features': [2, 4, 6, 8]},\n",
    "    # puis essaye 6 (2×3) combinaisons avec bootstrap à False (True étant la valeur par défaut)\n",
    "    {'bootstrap': [False], 'n_estimators': [3, 10], 'max_features': [2, 3, 4]},\n",
    "  ]\n",
    "\n",
    "forest_reg = RandomForestRegressor(random_state=42)\n",
    "\n",
    "# 5 sous-jeux de cross-val, ça fait en tout (12+6)*5=90 tours d'entraînement \n",
    "grid_search = GridSearchCV(forest_reg, param_grid, cv=5,\n",
    "                           scoring='neg_mean_squared_error', return_train_score=True)\n",
    "grid_search.fit(X_test_prepared, Y_test_set)\n",
    "grid_search.best_params_"
   ]
  },
  {
   "source": [
    "Affichage de la cross validation avec les meilleurs paramètres determiné par la grid search"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Scores: [0.19795466 0.20636669 0.21640563 0.17151853 0.17504152 0.18552252\n 0.21261112 0.21185778 0.20573182 0.19484639]\nMean: 0.19778566533660935\nStandard deviation: 0.015058579611401082\n"
     ]
    }
   ],
   "source": [
    "cv_res = grid_search.cv_results_\n",
    "forest_predicted = RandomForestRegressor(max_features=3, n_estimators=10, random_state=42)\n",
    "forest_predicted.fit(X_test_prepared, Y_test_set)\n",
    "forest_scores = cross_val_score(forest_predicted, X_test_prepared, Y_test_set,\n",
    "                                scoring=\"neg_mean_squared_error\", cv=10)\n",
    "forest_rmse_scores = np.sqrt(-forest_scores)\n",
    "display_scores(forest_rmse_scores)"
   ]
  },
  {
   "source": [
    "Les résultats montrent une légère amélioration de la fiabilité grâce aux nouveaux hyperparamètres "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Randomized Search\n",
    "\n",
    "Recherche des meilleurs parametres avec une grille aléatoire"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.1997390542155595 {'max_features': 7, 'n_estimators': 180}\n0.2061811561603739 {'max_features': 15, 'n_estimators': 107}\n0.19834308282026414 {'max_features': 8, 'n_estimators': 189}\n0.20089823947231547 {'max_features': 7, 'n_estimators': 122}\n0.20806106239456368 {'max_features': 19, 'n_estimators': 75}\n0.20383527906791926 {'max_features': 11, 'n_estimators': 88}\n0.1971500144108376 {'max_features': 4, 'n_estimators': 104}\n0.19466216677394352 {'max_features': 3, 'n_estimators': 150}\n0.1943673013533486 {'max_features': 2, 'n_estimators': 88}\n0.20331904062740502 {'max_features': 12, 'n_estimators': 158}\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import randint\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "param_distribs = {\n",
    "        'n_estimators': randint(low=1, high=200),\n",
    "        'max_features': randint(low=1, high=20),\n",
    "    }\n",
    "\n",
    "random_search = RandomizedSearchCV(forest_reg, param_distributions=param_distribs, cv=5,\n",
    "                           scoring='neg_mean_squared_error', return_train_score=True, random_state=42)\n",
    "random_search.fit(X_test_prepared, Y_test_set)\n",
    "random_srch = random_search.cv_results_\n",
    "\n",
    "for mean_score, param in zip(random_srch['mean_test_score'], random_srch['params']):\n",
    "    print(np.sqrt(-mean_score), param)\n",
    "\n",
    "    #Sort  the result"
   ]
  },
  {
   "source": [
    "## Importance de chaque attribut"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[(0.07643581117998811, 'MeanWorkingTime'),\n",
       " (0.07323570482539525, 'Age'),\n",
       " (0.06549139530591457, 'TotalWorkingYears'),\n",
       " (0.06171282078992841, 'MonthlyIncome'),\n",
       " (0.0584762774732892, 'YearsAtCompany'),\n",
       " (0.04802713593767167, 'DistanceFromHome'),\n",
       " (0.04771630039496903, 'PercentSalaryHike'),\n",
       " (0.04468606891057494, 'NumCompaniesWorked'),\n",
       " (0.044355824635589375, 'YearsWithCurrManager'),\n",
       " (0.03820293717257646, 'Married'),\n",
       " (0.03605800163153158, 'EnvironmentSatisfaction'),\n",
       " (0.03547613988473491, 'Unnamed: 0'),\n",
       " (0.03395832325845624, 'JobSatisfaction'),\n",
       " (0.03376526879775789, 'YearsSinceLastPromotion'),\n",
       " (0.03196689422977125, 'WorkLifeBalance'),\n",
       " (0.031900228185072474, 'TrainingTimesLastYear'),\n",
       " (0.030595610512323325, 'Divorced'),\n",
       " (0.0300497940705089, 'Education'),\n",
       " (0.027256915815805458, 'JobLevel'),\n",
       " (0.025398690055545178, 'JobInvolvement'),\n",
       " (0.02421166834994116, 'StockOptionLevel'),\n",
       " (0.021067676560164214, 'Single'),\n",
       " (0.016956106769926704, 'Gender'),\n",
       " (0.01026378430103669, 'PerformanceRating')]"
      ]
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "source": [
    "feature_importances = random_search.best_estimator_.feature_importances_\n",
    "cat_encoder = full_pipeline.named_transformers_[\"cat\"]\n",
    "cat_one_hot_attribs = list(cat_encoder.categories_[0])\n",
    "attributes = num_attribs + cat_one_hot_attribs\n",
    "sorted(zip(feature_importances, attributes), reverse=True)"
   ]
  },
  {
   "source": [
    "On peut voir que StandardHours, Over18 et EmployeeCount n'ont pas d'influence sur le model. On peut donc les drop pour optimiser l'efficacité des models"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "# Evaluation avec le meilleur modèle\n",
    "\n",
    "On évalue maintenant le reste du jeu de donné avec le modèle le plus performant"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.1622225158562368\n"
     ]
    }
   ],
   "source": [
    "from statistics import mean\n",
    "final_model = random_search.best_estimator_\n",
    "X_full_prepared = full_pipeline.transform(X_full_set)\n",
    "X_predictions = final_model.predict(X_full_prepared)\n",
    "\n",
    "final_mse = mean_squared_error(Y_full_set, X_predictions)\n",
    "final_rmse = np.sqrt(final_mse)\n",
    "print(mean(X_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (4300,) (9,) ",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-32-51ddeb3dacf8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;31m# plt.plot(np.array(x), np.array(y), 'ro')\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnewPrediction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'MeanWorkingTime'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'bo'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m \u001b[1;31m# plt.axis([0, 1, 0, 1])\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-32-51ddeb3dacf8>\u001b[0m in \u001b[0;36mnewPrediction\u001b[1;34m(attribut, coef)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mnewPrediction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mattribut\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcoef\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mX2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDataMerge\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0mX2\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mattribut\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX2\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mattribut\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mcoef\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m     \u001b[0mX2_labels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX2\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"Attrition\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mX2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Attrition\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda\\lib\\site-packages\\pandas\\core\\ops\\common.py\u001b[0m in \u001b[0;36mnew_method\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m     63\u001b[0m         \u001b[0mother\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mitem_from_zerodim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mother\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 65\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mother\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     66\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mnew_method\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda\\lib\\site-packages\\pandas\\core\\ops\\__init__.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(left, right)\u001b[0m\n\u001b[0;32m    341\u001b[0m         \u001b[0mlvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mextract_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mleft\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mextract_numpy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    342\u001b[0m         \u001b[0mrvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mextract_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mright\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mextract_numpy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 343\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marithmetic_op\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    344\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    345\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mleft\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_construct_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mres_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda\\lib\\site-packages\\pandas\\core\\ops\\array_ops.py\u001b[0m in \u001b[0;36marithmetic_op\u001b[1;34m(left, right, op)\u001b[0m\n\u001b[0;32m    188\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    189\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merrstate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"ignore\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 190\u001b[1;33m             \u001b[0mres_values\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mna_arithmetic_op\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    191\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    192\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mres_values\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda\\lib\\site-packages\\pandas\\core\\ops\\array_ops.py\u001b[0m in \u001b[0;36mna_arithmetic_op\u001b[1;34m(left, right, op, is_cmp)\u001b[0m\n\u001b[0;32m    141\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    142\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 143\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mexpressions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mleft\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mright\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    144\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    145\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mis_cmp\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda\\lib\\site-packages\\pandas\\core\\computation\\expressions.py\u001b[0m in \u001b[0;36mevaluate\u001b[1;34m(op, a, b, use_numexpr)\u001b[0m\n\u001b[0;32m    231\u001b[0m         \u001b[0muse_numexpr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0muse_numexpr\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0m_bool_arith_check\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mop_str\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    232\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0muse_numexpr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 233\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0m_evaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop_str\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# type: ignore\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    234\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0m_evaluate_standard\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop_str\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    235\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda\\lib\\site-packages\\pandas\\core\\computation\\expressions.py\u001b[0m in \u001b[0;36m_evaluate_numexpr\u001b[1;34m(op, op_str, a, b)\u001b[0m\n\u001b[0;32m    117\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    118\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 119\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_evaluate_standard\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop_str\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    120\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    121\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda\\lib\\site-packages\\pandas\\core\\computation\\expressions.py\u001b[0m in \u001b[0;36m_evaluate_standard\u001b[1;34m(op, op_str, a, b)\u001b[0m\n\u001b[0;32m     66\u001b[0m         \u001b[0m_store_test_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merrstate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"ignore\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 68\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     69\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     70\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: operands could not be broadcast together with shapes (4300,) (9,) "
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "def newPrediction(attribut, coef): \n",
    "    X2 = DataMerge()\n",
    "    X2[attribut] = X2[attribut] * coef\n",
    "    X2_labels = X2[\"Attrition\"].copy()\n",
    "    X2 = X2.drop(\"Attrition\", axis=1)\n",
    "    X2.Gender.replace(to_replace=dict(Male=1, Female=0), inplace=True)\n",
    "    X2_full_set, X2_test_set, Y2_full_set, Y2_test_set = train_test_split(X2, X2_labels, test_size=0.8, random_state=42) #SOLUTION\n",
    "    X2_full_prepared = full_pipeline.transform(X2_full_set)\n",
    "    X2_predictions = final_model.predict(X2_full_prepared)\n",
    "    return str(mean(X2_predictions))\n",
    "coefArray = np.arange(0.1, 1.0, 0.1)\n",
    "\n",
    "for i in coefArray:\n",
    "    iStr = str(i)\n",
    "    # print('Moyenne d\\'attrition : ' + newPrediction('MeanWorkingTime', i) + ', coef :' + iStr)\n",
    "    x.append(i)\n",
    "    y.append(newPrediction('MeanWorkingTime', i))\n",
    "\n",
    "# plt.plot(np.array(x), np.array(y), 'ro')\n",
    "plt.figure()\n",
    "plt.plot(coefArray, newPrediction('MeanWorkingTime', coefArray), 'bo')\n",
    "# plt.axis([0, 1, 0, 1])\n",
    "plt.show()"
   ]
  },
  {
   "source": [
    "Le meilleur résultat de fiabilité que l'on peut obtenir avec le jeu de validation."
   ],
   "cell_type": "markdown",
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}