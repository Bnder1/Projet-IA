{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression lineaire"
   ]
  },
  {
   "source": [
    "### Recuperation des donnés\n",
    "\n",
    "On vient récuperer les données préparés et stockés dans DataMerge.csv.   \n",
    "Ensuite on construit nos matrices avec une pipeline qui supprime les données incohérentes, réduit les éléments numériques à la même échelle et encode les valeurs non-numériques.\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[-1.73800917,  0.25240281,  1.15735878, ...,  2.        ,\n",
       "         2.        ,  1.        ],\n",
       "       [-1.73722299,  0.25240281, -0.65794042, ...,  1.        ,\n",
       "         1.        ,  1.        ],\n",
       "       [-1.73643681, -0.66194603, -0.65794042, ...,  1.        ,\n",
       "         1.        ,  4.        ],\n",
       "       ...,\n",
       "       [ 1.72590965,  1.16675164,  1.15735878, ...,  2.        ,\n",
       "         1.        ,  3.        ],\n",
       "       [ 1.72669583, -1.57629486,  0.24970918, ...,  2.        ,\n",
       "         1.        ,  1.        ],\n",
       "       [ 1.72748201,  1.16675164, -1.56559001, ...,  2.        ,\n",
       "         2.        ,  3.        ]])"
      ]
     },
     "metadata": {},
     "execution_count": 22
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "DATA_MERGE_PATH = os.path.join(\"data\")\n",
    "def DataMerge(data_merge_path=DATA_MERGE_PATH):\n",
    "    csv_path = os.path.join(data_merge_path, \"DataMerge.csv\")\n",
    "    return pd.read_csv(csv_path) \n",
    "\n",
    "X = DataMerge()\n",
    "\n",
    "\n",
    "X_labels = X[\"Attrition\"].copy()\n",
    "X = X.drop(\"Attrition\", axis=1)\n",
    "\n",
    "#remplace gender male=1 / female=0\n",
    "X.Gender.replace(to_replace=dict(Male=1, Female=0), inplace=True)\n",
    "X_full_set, X_test_set, Y_full_set, Y_test_set = train_test_split(X, X_labels, test_size=0.8, random_state=42) #SOLUTION\n",
    "num_pipeline = Pipeline([\n",
    "        ('imputer', SimpleImputer(strategy=\"median\")),\n",
    "        ('std_scaler', StandardScaler()),\n",
    "    ])\n",
    " \n",
    "X_num = X.select_dtypes(include=[np.number])\n",
    " \n",
    "num_attribs = list(X_num)\n",
    "cat_attribs = [\"MaritalStatus\", \"JobRole\", \"BusinessTravel\", \"Department\", \"EducationField\"]\n",
    " \n",
    "full_pipeline = ColumnTransformer([\n",
    "        (\"num\", num_pipeline, num_attribs),\n",
    "        (\"cat\", OrdinalEncoder(), cat_attribs),\n",
    "    ])\n",
    " \n",
    "X_test_prepared = full_pipeline.fit_transform(X_test_set)\n",
    "\n",
    "\n",
    "#Visualisation\n",
    "pd.set_option('display.max_columns', None)\n",
    "X_prepared\n",
    "\n"
   ]
  },
  {
   "source": [
    "Utilisation du modèle de régression linéaire. Le modèle cherche à determiner une corréleation entre les données étiquetable et les données etiquettes à travers une fonction.\n",
    "Après avoir entrainer le modèle, on test les prédictions sur quelques instances aléatoires."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Predictions: [0.04386169 0.29336635 0.2202775  0.00857749 0.30629663]\nLabels: [0, 1, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "lin_reg = LinearRegression()\n",
    "lin_reg.fit(X_test_prepared, Y_test_set)\n",
    "# On applique le full_pipeline sur quelques instances :\n",
    "some_data = X.iloc[:5]\n",
    "some_labels = X_labels.iloc[:5]\n",
    "some_data_prepared = full_pipeline.transform(some_data)\n",
    "\n",
    "# Et on effectue la prédiction :\n",
    "print(\"Predictions:\", lin_reg.predict(some_data_prepared))\n",
    "print(\"Labels:\", list(some_labels)) # vraies valeurs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation du modele\n",
    "\n",
    "On vient calculer la fiabilité de la régression linéaire pour ensuite comparer les modèles entre eux."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.3437275531620965"
      ]
     },
     "metadata": {},
     "execution_count": 28
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from math import *\n",
    "X_predictions = lin_reg.predict(X_test_prepared)\n",
    "lin_rmse = sqrt(mean_squared_error(Y_test_set, X_predictions ))\n",
    "lin_rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Arbre de décision\n",
    "\n",
    "Entrainement d'un arbre de décision."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "metadata": {},
     "execution_count": 29
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "tree_reg = DecisionTreeRegressor(random_state=42)\n",
    "tree_reg.fit(X_test_prepared, Y_test_set)\n",
    "X_predictions = tree_reg.predict(X_test_prepared)\n",
    "tree_mse = mean_squared_error(Y_test_set, X_predictions)\n",
    "tree_rmse = np.sqrt(tree_mse)\n",
    "tree_rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ici l'évaluation du modèle returne 0 soit un apprentissage parfait. Or ceci est impossible en Machine Learning. On peut donc en déduire que le modèle à fait de l'overfitting.   \n",
    "En effet celui ci a appri toutes les combinaison possible du jeu de données qui lui a été soumis pour le fitting. "
   ]
  },
  {
   "source": [
    "# Cross Validation\n",
    "\n",
    "La cross-validation permet d'evaluer la fiabilité du model en testant des échantillons du jeu de données."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Arbre de decision"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Scores: [0.23501608 0.27492071 0.27492071 0.17882042 0.21566555 0.26413527\n 0.23501608 0.24707592 0.29034863 0.25289027]\nMean: 0.2468809638564653\nStandard deviation: 0.031119034953955408\nScores: [0.44460591 0.44460591 0.45749571 0.47003216 0.45749571 0.47003216\n 0.43133109 0.45749571 0.49415185 0.43133109]\nMean: 0.4558577314255869\nStandard deviation: 0.018255508298547992\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "scores = cross_val_score(tree_reg, X_test_prepared, Y_test_set,\n",
    "                         scoring=\"neg_mean_squared_error\", cv=10)\n",
    "tree_rmse_scores = np.sqrt(-scores)\n",
    "#Calcul du score avec le jeu de validation\n",
    "new_scores = cross_val_score(tree_reg, X_full_prepared, Y_full_set,\n",
    "                         scoring=\"neg_mean_squared_error\", cv=10)\n",
    "new_tree_rmse_scores = np.sqrt(-new_scores)\n",
    "def display_scores(scores):\n",
    "    print(\"Scores:\", scores)\n",
    "    print(\"Mean:\", scores.mean())\n",
    "    print(\"Standard deviation:\", scores.std())\n",
    "\n",
    "display_scores(tree_rmse_scores)\n",
    "display_scores(new_tree_rmse_scores)"
   ]
  },
  {
   "source": [
    "On voit ici que la fiabilité n'est plus a 0. Donc le modèle n'est pas assez performant sur un jeu de donné inconnu."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Regression Lineaire\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Scores: [0.33465968 0.33240475 0.37284842 0.32991516 0.33355488 0.32199852\n 0.36119033 0.36038367 0.3699375  0.34570255]\nMean: 0.3462595458753298\nStandard deviation: 0.017418379453167095\n"
     ]
    }
   ],
   "source": [
    "scores = cross_val_score(lin_reg, X_test_prepared, Y_test_set,\n",
    "                         scoring=\"neg_mean_squared_error\", cv=10)\n",
    "lin_rmse_scores = np.sqrt(-scores)\n",
    "display_scores(lin_rmse_scores)"
   ]
  },
  {
   "source": [
    "# Foret Aléatoire"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.0890192035723257"
      ]
     },
     "metadata": {},
     "execution_count": 41
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "forest_reg = RandomForestRegressor(n_estimators=10, random_state=42)\n",
    "forest_reg.fit(X_test_prepared, Y_test_set)\n",
    "X_predictions = forest_reg.predict(X_test_prepared)\n",
    "forest_rmse = mean_squared_error(Y_test_set, X_predictions)\n",
    "forest_rmse = np.sqrt(forest_rmse)\n",
    "forest_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Scores: [0.20324404 0.23259157 0.22938239 0.18677184 0.19199079 0.1768589\n 0.2342107  0.23674144 0.23020466 0.1996363 ]\nMean: 0.2121632628353299\nStandard deviation: 0.02159632065555168\n"
     ]
    }
   ],
   "source": [
    "forest_scores = cross_val_score(forest_reg, X_test_prepared, Y_test_set,\n",
    "                                scoring=\"neg_mean_squared_error\", cv=10)\n",
    "forest_rmse_scores = np.sqrt(-forest_scores)\n",
    "display_scores(forest_rmse_scores)"
   ]
  },
  {
   "source": [
    "## Support Vector Regression "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.3728904196607226"
      ]
     },
     "metadata": {},
     "execution_count": 35
    }
   ],
   "source": [
    "from sklearn.svm import SVR\n",
    "svr_regr = SVR(kernel=\"linear\")\n",
    "svr_regr.fit(X_test_prepared, Y_test_set)\n",
    "X_predictions = svr_regr.predict(X_test_prepared)\n",
    "svr_mse = mean_squared_error(Y_test_set, X_predictions)\n",
    "svr_rmse = np.sqrt(svr_mse)\n",
    "svr_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Scores: [0.34871446 0.35857218 0.41001831 0.36815984 0.35532436 0.32454261\n 0.39559787 0.3955853  0.40716693 0.35531165]\nMean: 0.3718993498620441\nStandard deviation: 0.02709461442729581\n"
     ]
    }
   ],
   "source": [
    "svr_regr_scores = cross_val_score(svr_regr, X_test_prepared, Y_test_set,\n",
    "                                scoring=\"neg_mean_squared_error\", cv=10)\n",
    "svr_regr_rmse_scores = np.sqrt(-svr_regr_scores)\n",
    "display_scores(svr_regr_rmse_scores)"
   ]
  },
  {
   "source": [
    "## Grid Search\n",
    "\n",
    "Recherche des meilleurs paramètres.\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'bootstrap': False, 'max_features': 3, 'n_estimators': 10}"
      ]
     },
     "metadata": {},
     "execution_count": 42
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = [\n",
    "    # essaye 12 (3×4) combinaisons des hyperparametres\n",
    "    {'n_estimators': [3, 10, 30], 'max_features': [2, 4, 6, 8]},\n",
    "    # puis essaye 6 (2×3) combinaisons avec bootstrap à False (True étant la valeur par défaut)\n",
    "    {'bootstrap': [False], 'n_estimators': [3, 10], 'max_features': [2, 3, 4]},\n",
    "  ]\n",
    "\n",
    "forest_reg = RandomForestRegressor(random_state=42)\n",
    "\n",
    "# 5 sous-jeux de cross-val, ça fait en tout (12+6)*5=90 tours d'entraînement \n",
    "grid_search = GridSearchCV(forest_reg, param_grid, cv=5,\n",
    "                           scoring='neg_mean_squared_error', return_train_score=True)\n",
    "grid_search.fit(X_test_prepared, Y_test_set)\n",
    "grid_search.best_params_"
   ]
  },
  {
   "source": [
    "Affichage de la cross validation avec les meilleurs paramètres determiné par la grid search"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Scores: [0.19795466 0.20636669 0.21640563 0.17151853 0.17504152 0.18552252\n 0.21261112 0.21185778 0.20573182 0.19484639]\nMean: 0.19778566533660935\nStandard deviation: 0.015058579611401082\n"
     ]
    }
   ],
   "source": [
    "cv_res = grid_search.cv_results_\n",
    "forest_predicted = RandomForestRegressor(max_features=3, n_estimators=10, random_state=42)\n",
    "forest_predicted.fit(X_test_prepared, Y_test_set)\n",
    "forest_scores = cross_val_score(forest_predicted, X_test_prepared, Y_test_set,\n",
    "                                scoring=\"neg_mean_squared_error\", cv=10)\n",
    "forest_rmse_scores = np.sqrt(-forest_scores)\n",
    "display_scores(forest_rmse_scores)"
   ]
  },
  {
   "source": [
    "Les résultats montrent une légère amélioration de la fiabilité grâce aux nouveaux hyperparamètres "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Randomized Search\n",
    "\n",
    "Recherche des meilleurs parametres avec une grille aléatoire"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.1997390542155595 {'max_features': 7, 'n_estimators': 180}\n0.2061811561603739 {'max_features': 15, 'n_estimators': 107}\n0.19834308282026414 {'max_features': 8, 'n_estimators': 189}\n0.20089823947231547 {'max_features': 7, 'n_estimators': 122}\n0.20806106239456368 {'max_features': 19, 'n_estimators': 75}\n0.20383527906791926 {'max_features': 11, 'n_estimators': 88}\n0.1971500144108376 {'max_features': 4, 'n_estimators': 104}\n0.19466216677394352 {'max_features': 3, 'n_estimators': 150}\n0.1943673013533486 {'max_features': 2, 'n_estimators': 88}\n0.20331904062740502 {'max_features': 12, 'n_estimators': 158}\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import randint\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "param_distribs = {\n",
    "        'n_estimators': randint(low=1, high=200),\n",
    "        'max_features': randint(low=1, high=20),\n",
    "    }\n",
    "\n",
    "random_search = RandomizedSearchCV(forest_reg, param_distributions=param_distribs, cv=5,\n",
    "                           scoring='neg_mean_squared_error', return_train_score=True, random_state=42)\n",
    "random_search.fit(X_test_prepared, Y_test_set)\n",
    "random_srch = random_search.cv_results_\n",
    "\n",
    "for mean_score, param in zip(random_srch['mean_test_score'], random_srch['params']):\n",
    "    print(np.sqrt(-mean_score), param)\n",
    "\n",
    "    #Sort  the result"
   ]
  },
  {
   "source": [
    "## Importance de chaque attribut"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[(0.07643581117998811, 'MeanWorkingTime'),\n",
       " (0.07323570482539525, 'Age'),\n",
       " (0.06549139530591457, 'TotalWorkingYears'),\n",
       " (0.06171282078992841, 'MonthlyIncome'),\n",
       " (0.0584762774732892, 'YearsAtCompany'),\n",
       " (0.04802713593767167, 'DistanceFromHome'),\n",
       " (0.04771630039496903, 'PercentSalaryHike'),\n",
       " (0.04468606891057494, 'NumCompaniesWorked'),\n",
       " (0.044355824635589375, 'YearsWithCurrManager'),\n",
       " (0.03820293717257646, 'Married'),\n",
       " (0.03605800163153158, 'EnvironmentSatisfaction'),\n",
       " (0.03547613988473491, 'Unnamed: 0'),\n",
       " (0.03395832325845624, 'JobSatisfaction'),\n",
       " (0.03376526879775789, 'YearsSinceLastPromotion'),\n",
       " (0.03196689422977125, 'WorkLifeBalance'),\n",
       " (0.031900228185072474, 'TrainingTimesLastYear'),\n",
       " (0.030595610512323325, 'Divorced'),\n",
       " (0.0300497940705089, 'Education'),\n",
       " (0.027256915815805458, 'JobLevel'),\n",
       " (0.025398690055545178, 'JobInvolvement'),\n",
       " (0.02421166834994116, 'StockOptionLevel'),\n",
       " (0.021067676560164214, 'Single'),\n",
       " (0.016956106769926704, 'Gender'),\n",
       " (0.01026378430103669, 'PerformanceRating')]"
      ]
     },
     "metadata": {},
     "execution_count": 52
    }
   ],
   "source": [
    "feature_importances = random_search.best_estimator_.feature_importances_\n",
    "cat_encoder = full_pipeline.named_transformers_[\"cat\"]\n",
    "cat_one_hot_attribs = list(cat_encoder.categories_[0])\n",
    "attributes = num_attribs + cat_one_hot_attribs\n",
    "sorted(zip(feature_importances, attributes), reverse=True)"
   ]
  },
  {
   "source": [
    "On peut voir que StandardHours, Over18 et EmployeeCount n'ont pas d'influence sur le model. On peut donc les drop pour optimiser l'efficacité des models"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "# Evaluation avec le meilleur modèle\n",
    "\n",
    "On évalue maintenant le reste du jeu de donné avec le modèle le plus performant"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.1691860465116279\n"
     ]
    }
   ],
   "source": [
    "from statistics import mean\n",
    "final_model = random_search.best_estimator_\n",
    "X_full_prepared = full_pipeline.transform(X_full_set)\n",
    "X_predictions = final_model.predict(X_full_prepared)\n",
    "print(mean(X_predictions))\n",
    "final_mse = mean_squared_error(Y_full_set, X_predictions)\n",
    "final_rmse = np.sqrt(final_mse)\n",
    "# final_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.1589455602536998\n"
     ]
    }
   ],
   "source": [
    "X2 = DataMerge()\n",
    "X2['MeanWorkingTime'] = X2['MeanWorkingTime'] / 2\n",
    "X2_labels = X2[\"Attrition\"].copy()\n",
    "X2 = X2.drop(\"Attrition\", axis=1)\n",
    "\n",
    "#remplace gender male=1 / female=0\n",
    "X2.Gender.replace(to_replace=dict(Male=1, Female=0), inplace=True)\n",
    "X2_full_set, X2_test_set, Y2_full_set, Y2_test_set = train_test_split(X2, X2_labels, test_size=0.8, random_state=42) #SOLUTION\n",
    "X2_full_prepared = full_pipeline.transform(X2_full_set)\n",
    "X2_predictions = final_model.predict(X2_full_prepared)\n",
    "print(mean(X2_predictions))"
   ]
  },
  {
   "source": [
    "Le meilleur résultat de fiabilité que l'on peut obtenir avec le jeu de validation."
   ],
   "cell_type": "markdown",
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}