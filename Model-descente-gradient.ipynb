{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression lineaire"
   ]
  },
  {
   "source": [
    "### Recuperation des donnés\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[-1.73800917,  0.25240281,  1.15735878, ...,  2.        ,\n",
       "         2.        ,  1.        ],\n",
       "       [-1.73722299,  0.25240281, -0.65794042, ...,  1.        ,\n",
       "         1.        ,  1.        ],\n",
       "       [-1.73643681, -0.66194603, -0.65794042, ...,  1.        ,\n",
       "         1.        ,  4.        ],\n",
       "       ...,\n",
       "       [ 1.72590965,  1.16675164,  1.15735878, ...,  2.        ,\n",
       "         1.        ,  3.        ],\n",
       "       [ 1.72669583, -1.57629486,  0.24970918, ...,  2.        ,\n",
       "         1.        ,  1.        ],\n",
       "       [ 1.72748201,  1.16675164, -1.56559001, ...,  2.        ,\n",
       "         2.        ,  3.        ]])"
      ]
     },
     "metadata": {},
     "execution_count": 22
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "DATA_MERGE_PATH = os.path.join(\"data\")\n",
    "def DataMerge(data_merge_path=DATA_MERGE_PATH):\n",
    "    csv_path = os.path.join(data_merge_path, \"DataMerge.csv\")\n",
    "    return pd.read_csv(csv_path) \n",
    "\n",
    "X = DataMerge()\n",
    "\n",
    "\n",
    "X_labels = X[\"Attrition\"].copy()\n",
    "X = X.drop(\"Attrition\", axis=1)\n",
    "\n",
    "#remplace gender male=1 / female=0\n",
    "X.Gender.replace(to_replace=dict(Male=1, Female=0), inplace=True)\n",
    "X_full_set, X_test_set, Y_full_set, Y_test_set = train_test_split(X, X_labels, test_size=0.8, random_state=42) #SOLUTION\n",
    "num_pipeline = Pipeline([\n",
    "        ('imputer', SimpleImputer(strategy=\"median\")),\n",
    "        ('std_scaler', StandardScaler()),\n",
    "    ])\n",
    " \n",
    "X_num = X.select_dtypes(include=[np.number])\n",
    " \n",
    "num_attribs = list(X_num)\n",
    "cat_attribs = [\"MaritalStatus\", \"JobRole\", \"BusinessTravel\", \"Department\", \"EducationField\"]\n",
    " \n",
    "full_pipeline = ColumnTransformer([\n",
    "        (\"num\", num_pipeline, num_attribs),\n",
    "        (\"cat\", OrdinalEncoder(), cat_attribs),\n",
    "    ])\n",
    " \n",
    "X_test_prepared = full_pipeline.fit_transform(X_test_set)\n",
    "\n",
    "\n",
    "#Visualisation\n",
    "pd.set_option('display.max_columns', None)\n",
    "X_prepared\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Predictions: [0.04386169 0.29336635 0.2202775  0.00857749 0.30629663]\nLabels: [0, 1, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "lin_reg = LinearRegression()\n",
    "lin_reg.fit(X_test_prepared, Y_test_set)\n",
    "# On applique le full_pipeline sur quelques instances :\n",
    "some_data = X.iloc[:5]\n",
    "some_labels = X_labels.iloc[:5]\n",
    "some_data_prepared = full_pipeline.transform(some_data)\n",
    "\n",
    "# Et on effectue la prédiction :\n",
    "print(\"Predictions:\", lin_reg.predict(some_data_prepared))\n",
    "print(\"Labels:\", list(some_labels)) # vraies valeurs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation du modele"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.3437275531620965"
      ]
     },
     "metadata": {},
     "execution_count": 28
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from math import *\n",
    "X_predictions = lin_reg.predict(X_test_prepared)\n",
    "lin_rmse = sqrt(mean_squared_error(Y_test_set, X_predictions ))\n",
    "lin_rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Arbre de décision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "metadata": {},
     "execution_count": 29
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "tree_reg = DecisionTreeRegressor(random_state=42)\n",
    "tree_reg.fit(X_test_prepared, Y_test_set)\n",
    "X_predictions = tree_reg.predict(X_test_prepared)\n",
    "tree_mse = mean_squared_error(Y_test_set, X_predictions)\n",
    "tree_rmse = np.sqrt(tree_mse)\n",
    "tree_rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0 => overfitting"
   ]
  },
  {
   "source": [
    "# Cross Validation"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Arbre de decision"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Scores: [0.23501608 0.27492071 0.27492071 0.17882042 0.21566555 0.26413527\n 0.23501608 0.24707592 0.29034863 0.25289027]\nMean: 0.2468809638564653\nStandard deviation: 0.031119034953955408\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "scores = cross_val_score(tree_reg, X_test_prepared, Y_test_set,\n",
    "                         scoring=\"neg_mean_squared_error\", cv=10)\n",
    "tree_rmse_scores = np.sqrt(-scores)\n",
    "def display_scores(scores):\n",
    "    print(\"Scores:\", scores)\n",
    "    print(\"Mean:\", scores.mean())\n",
    "    print(\"Standard deviation:\", scores.std())\n",
    "\n",
    "display_scores(tree_rmse_scores)"
   ]
  },
  {
   "source": [
    "## Regression Lineaire\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Scores: [0.33465968 0.33240475 0.37284842 0.32991516 0.33355488 0.32199852\n 0.36119033 0.36038367 0.3699375  0.34570255]\nMean: 0.3462595458753298\nStandard deviation: 0.017418379453167095\n"
     ]
    }
   ],
   "source": [
    "scores = cross_val_score(lin_reg, X_test_prepared, Y_test_set,\n",
    "                         scoring=\"neg_mean_squared_error\", cv=10)\n",
    "lin_rmse_scores = np.sqrt(-scores)\n",
    "display_scores(lin_rmse_scores)"
   ]
  },
  {
   "source": [
    "# Foret Aléatoire"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.0890192035723257"
      ]
     },
     "metadata": {},
     "execution_count": 41
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "forest_reg = RandomForestRegressor(n_estimators=10, random_state=42)\n",
    "forest_reg.fit(X_test_prepared, Y_test_set)\n",
    "X_predictions = forest_reg.predict(X_test_prepared)\n",
    "forest_rmse = mean_squared_error(Y_test_set, X_predictions)\n",
    "forest_rmse = np.sqrt(forest_rmse)\n",
    "forest_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Scores: [0.20324404 0.23259157 0.22938239 0.18677184 0.19199079 0.1768589\n 0.2342107  0.23674144 0.23020466 0.1996363 ]\nMean: 0.2121632628353299\nStandard deviation: 0.02159632065555168\n"
     ]
    }
   ],
   "source": [
    "forest_scores = cross_val_score(forest_reg, X_test_prepared, Y_test_set,\n",
    "                                scoring=\"neg_mean_squared_error\", cv=10)\n",
    "forest_rmse_scores = np.sqrt(-forest_scores)\n",
    "display_scores(forest_rmse_scores)"
   ]
  },
  {
   "source": [
    "## Support Vector Regression "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.3728904196607226"
      ]
     },
     "metadata": {},
     "execution_count": 35
    }
   ],
   "source": [
    "from sklearn.svm import SVR\n",
    "svr_regr = SVR(kernel=\"linear\")\n",
    "svr_regr.fit(X_test_prepared, Y_test_set)\n",
    "X_predictions = svr_regr.predict(X_test_prepared)\n",
    "svr_mse = mean_squared_error(Y_test_set, X_predictions)\n",
    "svr_rmse = np.sqrt(svr_mse)\n",
    "svr_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Scores: [0.34871446 0.35857218 0.41001831 0.36815984 0.35532436 0.32454261\n 0.39559787 0.3955853  0.40716693 0.35531165]\nMean: 0.3718993498620441\nStandard deviation: 0.02709461442729581\n"
     ]
    }
   ],
   "source": [
    "svr_regr_scores = cross_val_score(svr_regr, X_test_prepared, Y_test_set,\n",
    "                                scoring=\"neg_mean_squared_error\", cv=10)\n",
    "svr_regr_rmse_scores = np.sqrt(-svr_regr_scores)\n",
    "display_scores(svr_regr_rmse_scores)"
   ]
  },
  {
   "source": [
    "## Grid Search\n",
    "\n",
    "Recherche des meilleurs paramètres\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'bootstrap': False, 'max_features': 3, 'n_estimators': 10}"
      ]
     },
     "metadata": {},
     "execution_count": 42
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = [\n",
    "    # essaye 12 (3×4) combinaisons des hyperparametres\n",
    "    {'n_estimators': [3, 10, 30], 'max_features': [2, 4, 6, 8]},\n",
    "    # puis essaye 6 (2×3) combinaisons avec bootstrap à False (True étant la valeur par défaut)\n",
    "    {'bootstrap': [False], 'n_estimators': [3, 10], 'max_features': [2, 3, 4]},\n",
    "  ]\n",
    "\n",
    "forest_reg = RandomForestRegressor(random_state=42)\n",
    "\n",
    "# 5 sous-jeux de cross-val, ça fait en tout (12+6)*5=90 tours d'entraînement \n",
    "grid_search = GridSearchCV(forest_reg, param_grid, cv=5,\n",
    "                           scoring='neg_mean_squared_error', return_train_score=True)\n",
    "grid_search.fit(X_test_prepared, Y_test_set)\n",
    "grid_search.best_params_"
   ]
  },
  {
   "source": [
    "Affichage de la cross validation avec les meilleurs paramètres determiné par la grid search"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Scores: [0.19795466 0.20636669 0.21640563 0.17151853 0.17504152 0.18552252\n 0.21261112 0.21185778 0.20573182 0.19484639]\nMean: 0.19778566533660935\nStandard deviation: 0.015058579611401082\n"
     ]
    }
   ],
   "source": [
    "cv_res = grid_search.cv_results_\n",
    "forest_predicted = RandomForestRegressor(max_features=3, n_estimators=10, random_state=42)\n",
    "forest_predicted.fit(X_test_prepared, Y_test_set)\n",
    "forest_scores = cross_val_score(forest_predicted, X_test_prepared, Y_test_set,\n",
    "                                scoring=\"neg_mean_squared_error\", cv=10)\n",
    "forest_rmse_scores = np.sqrt(-forest_scores)\n",
    "display_scores(forest_rmse_scores)"
   ]
  },
  {
   "source": [
    "## Randomized Search\n",
    "\n",
    "Recherche des meilleurs parametres avec une grille aléatoire"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.1997390542155595 {'max_features': 7, 'n_estimators': 180}\n0.2061811561603739 {'max_features': 15, 'n_estimators': 107}\n0.19834308282026414 {'max_features': 8, 'n_estimators': 189}\n0.20089823947231547 {'max_features': 7, 'n_estimators': 122}\n0.20806106239456368 {'max_features': 19, 'n_estimators': 75}\n0.20383527906791926 {'max_features': 11, 'n_estimators': 88}\n0.1971500144108376 {'max_features': 4, 'n_estimators': 104}\n0.19466216677394352 {'max_features': 3, 'n_estimators': 150}\n0.1943673013533486 {'max_features': 2, 'n_estimators': 88}\n0.20331904062740502 {'max_features': 12, 'n_estimators': 158}\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import randint\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "param_distribs = {\n",
    "        'n_estimators': randint(low=1, high=200),\n",
    "        'max_features': randint(low=1, high=20),\n",
    "    }\n",
    "\n",
    "random_search = RandomizedSearchCV(forest_reg, param_distributions=param_distribs, cv=5,\n",
    "                           scoring='neg_mean_squared_error', return_train_score=True, random_state=42)\n",
    "random_search.fit(X_test_prepared, Y_test_set)\n",
    "random_srch = random_search.cv_results_\n",
    "\n",
    "for mean_score, param in zip(random_srch['mean_test_score'], random_srch['params']):\n",
    "    print(np.sqrt(-mean_score), param)\n",
    "\n",
    "    #Sort  the result"
   ]
  },
  {
   "source": [
    "## Importance de chaque attribut"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[(0.08439448773765947, 'MeanWorkingTime'),\n",
       " (0.07721351126847302, 'Age'),\n",
       " (0.07217076767868888, 'TotalWorkingYears'),\n",
       " (0.06939091991697881, 'MonthlyIncome'),\n",
       " (0.057224234476192126, 'YearsAtCompany'),\n",
       " (0.05124094249731204, 'DistanceFromHome'),\n",
       " (0.04665989744276224, 'PercentSalaryHike'),\n",
       " (0.04155720208252564, 'YearsWithCurrManager'),\n",
       " (0.04127779956510823, 'NumCompaniesWorked'),\n",
       " (0.03989794564282858, 'pop_per_hhold'),\n",
       " (0.03741750494522967, 'EnvironmentSatisfaction'),\n",
       " (0.035008020276149306, 'YearsSinceLastPromotion'),\n",
       " (0.03371380615477724, 'rooms_per_hhold'),\n",
       " (0.03279323532145874, 'JobSatisfaction'),\n",
       " (0.030582733885974652, 'TrainingTimesLastYear'),\n",
       " (0.029979877648911035, 'WorkLifeBalance'),\n",
       " (0.029411346746421856, 'Married'),\n",
       " (0.029377699191874627, 'Education'),\n",
       " (0.025639821985618136, 'Unnamed: 0'),\n",
       " (0.025492513154067042, 'JobLevel'),\n",
       " (0.024166814171409697, 'JobInvolvement'),\n",
       " (0.023077348138564272, 'StockOptionLevel'),\n",
       " (0.0193276256886605, 'bedrooms_per_room'),\n",
       " (0.01882448642606357, 'Divorced'),\n",
       " (0.015435863839668506, 'Gender'),\n",
       " (0.008723594116622109, 'PerformanceRating')]"
      ]
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "source": [
    "feature_importances = random_search.best_estimator_.feature_importances_\n",
    "cat_encoder = full_pipeline.named_transformers_[\"cat\"]\n",
    "cat_one_hot_attribs = list(cat_encoder.categories_[0])\n",
    "attributes = num_attribs + cat_one_hot_attribs\n",
    "sorted(zip(feature_importances, attributes), reverse=True)"
   ]
  },
  {
   "source": [
    "On peut voir que StandardHours, Over18 et EmployeeCount n'ont pas d'influence sur le model. On peut donc les drop pour optimiser l'efficacité des models"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "# Evaluation avec le meilleur modèle\n",
    "\n",
    "On évalue maintenant le reste du jeu de donné avec le modèle le plus performant"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.15152267634591338"
      ]
     },
     "metadata": {},
     "execution_count": 46
    }
   ],
   "source": [
    "final_model = random_search.best_estimator_\n",
    "X_full_prepared = full_pipeline.transform(X_full_set)\n",
    "X_predictions = final_model.predict(X_full_prepared)\n",
    "final_mse = mean_squared_error(Y_full_set, X_predictions)\n",
    "final_rmse = np.sqrt(final_mse)\n",
    "final_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}